{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#We imported a couple of packages. Let's create some sample data and add the line to this file:\n",
    "\n",
    "input_data = np.array([\n",
    "    [3, -1.5,   3,   -6.4],\n",
    "    [0,  3,    -1.3,  4.1],\n",
    "    [1,  2.3,  -2.9, -4.3]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =\n",
      " [[ 3.  -1.5  3.  -6.4]\n",
      " [ 0.   3.  -1.3  4.1]\n",
      " [ 1.   2.3 -2.9 -4.3]]\n",
      "\n",
      "Mean =  [  5.55111512e-17  -3.70074342e-17   0.00000000e+00  -1.85037171e-17]\n",
      "Std deviation =  [ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "data_standardized = preprocessing.scale(input_data)\n",
    "print(\"data =\\n\", input_data)\n",
    "print(\"\\nMean = \", data_standardized.mean(axis = 0))\n",
    "print(\"Std deviation = \", data_standardized.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =\n",
      " [[ 3.  -1.5  3.  -6.4]\n",
      " [ 0.   3.  -1.3  4.1]\n",
      " [ 1.   2.3 -2.9 -4.3]]\n",
      "\n",
      "Min max scaled data = \n",
      " [[ 1.          0.          1.          0.        ]\n",
      " [ 0.          1.          0.27118644  1.        ]\n",
      " [ 0.33333333  0.84444444  0.          0.2       ]]\n"
     ]
    }
   ],
   "source": [
    "data_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "print(\"data =\\n\", input_data)\n",
    "data_scaled = data_scaler.fit_transform(input_data)\n",
    "print(\"\\nMin max scaled data = \\n\", data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =\n",
      " [[ 3.  -1.5  3.  -6.4]\n",
      " [ 0.   3.  -1.3  4.1]\n",
      " [ 1.   2.3 -2.9 -4.3]]\n",
      "L1 normalized data =\n",
      " [[ 0.21582734 -0.10791367  0.21582734 -0.46043165]\n",
      " [ 0.          0.35714286 -0.1547619   0.48809524]\n",
      " [ 0.0952381   0.21904762 -0.27619048 -0.40952381]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = preprocessing.normalize(input_data, norm  = 'l1')\n",
    "print(\"data =\\n\", input_data)\n",
    "print(\"L1 normalized data =\\n\", data_normalized)\n",
    "np.sum(np.abs(data_normalized), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =\n",
      " [[ 3.  -1.5  3.  -6.4]\n",
      " [ 0.   3.  -1.3  4.1]\n",
      " [ 1.   2.3 -2.9 -4.3]]\n",
      "\n",
      "Binarized data =\n",
      " [[ 1.  0.  1.  0.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "data_binarized = preprocessing.Binarizer(threshold=1.4).transform(input_data)\n",
    "print(\"data =\\n\", input_data)\n",
    "print(\"\\nBinarized data =\\n\", data_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded vector =\n",
      " [[ 0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([  [0, 2, 1, 12], \n",
    "               [1, 3, 5, 3], \n",
    "               [2, 3, 2, 12], \n",
    "               [1, 2, 4, 3]\n",
    "])\n",
    "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
    "print(\"\\nEncoded vector =\\n\", encoded_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class mapping:\n",
      "\t bmw --> 0\n",
      "\t ford --> 1\n",
      "\t suzuki --> 2\n",
      "\t toyota --> 3\n",
      "\n",
      "\n",
      "\n",
      "Labels = ['toyota', 'ford', 'suzuki']\n",
      "Encoded labels = [3, 1, 2]\n",
      "\n",
      "\n",
      "\n",
      "Encoded labels = [3, 2, 0, 2, 1]\n",
      "Decoded labels = ['toyota', 'suzuki', 'bmw', 'suzuki', 'ford']\n"
     ]
    }
   ],
   "source": [
    "input_classes = ['suzuki', 'ford', 'suzuki', 'toyota', 'ford', 'bmw']\n",
    "label_encoder = preprocessing.LabelEncoder().fit(input_classes)\n",
    "print(\"\\nClass mapping:\")\n",
    "for i, item in enumerate(label_encoder.classes_):\n",
    "    print('\\t', item, '-->', i)\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "labels = ['toyota', 'ford', 'suzuki']\n",
    "encoded_labels = label_encoder.transform(labels)\n",
    "print(\"\\nLabels =\", labels)\n",
    "print(\"Encoded labels =\", list(encoded_labels))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "encoded_labels = [3, 2, 0, 2, 1]\n",
    "decoded_labels = label_encoder.inverse_transform(encoded_labels)\n",
    "print(\"\\nEncoded labels =\", encoded_labels)\n",
    "print(\"Decoded labels =\", list(decoded_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
